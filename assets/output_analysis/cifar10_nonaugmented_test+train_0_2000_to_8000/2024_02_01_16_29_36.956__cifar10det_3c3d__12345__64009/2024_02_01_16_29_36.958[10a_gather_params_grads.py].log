["2024-02-01_16:29:36.961", ["CONFIG", {"OBS_DATASETS": "/mnt/qb/work/REDACTED/REDACTED/datasets/DeepOBS", "TUNING_CONF": "config/basic_config.yaml", "OPTIMIZER": "SGD", "PROBLEM": "cifar10det_3c3d", "RANDOM_SEED": 12345, "MAX_STEPS": 8001, "DEVICE": "cuda", "OUTPUT_DIR": "output", "OUTDIR_SUFFIX": "64009", "RECORD_STEPS": [0, 2000, 4000, 6000, 8000], "NUM_HESSIAN_DATAPOINTS": 500, "STORE_GRADS": false}]]
["2024-02-01_16:30:04.314", ["GLOBALS", {"run_dir": "output/2024_02_01_16_29_36.956__cifar10det_3c3d__12345__64009", "batch_size": 128, "num_epochs": 100, "max_steps": 8001, "steps_per_epoch": 312, "opt_name": "SGD", "opt_hpars": {"lr": 0.022610510812765}, "sched_name": null, "sched_hpars": null, "param_shapes": [[64, 3, 5, 5], [64], [96, 64, 3, 3], [96], [128, 96, 3, 3], [128], [512, 1152], [512], [256, 512], [256], [10, 256], [10]], "num_params": 895210, "H_train_idxs": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 433, 434, 435, 436, 437, 439, 440, 441, 442, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 462, 463, 465, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 479, 481, 483, 484, 485, 487, 489, 490, 491, 492, 494, 496, 499, 500, 501, 502, 503, 507, 509, 510, 513, 515, 517, 518, 522, 533, 534, 535, 538, 539, 542, 548, 550, 569, 573, 607, 624, 653], "H_test_idxs": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 448, 449, 450, 452, 453, 455, 456, 457, 458, 460, 462, 463, 464, 465, 466, 467, 468, 470, 471, 474, 475, 478, 479, 483, 484, 488, 490, 493, 494, 497, 500, 502, 503, 505, 506, 509, 510, 513, 515, 521, 523, 528, 540, 546, 555, 557, 572, 580, 583, 587, 594, 604, 619, 622, 629], "record_steps": [0, 2000, 4000, 6000, 8000]}]]
["2024-02-01_16:30:12.369", ["EVAL ROUND", {"epoch": 1, "global_step": 0, "train_loss": 65.33866823636569, "train_acc": 0.10016025641025642, "xv_loss": 65.33677908090445, "xv_acc": 0.10166266025641026, "test_loss": 65.33851330096905, "test_acc": 0.10016025641025642}]]
["2024-02-01_16:30:12.453", ["HDF5", {"global_step": 0, "matrix": "batch_parameters", "split": "batch", "status": "saved"}]]
["2024-02-01_16:30:13.041", ["TRAINING BATCH", {"global_step": 0, "epoch": 1, "batch_loss": 2.343777656555176, "H_train_loss": 2.3381620292663574, "H_test_loss": 2.339209613800049, "lr": 0.022610510812765}]]
["2024-02-01_16:30:28.367", ["EVAL ROUND", {"epoch": 2, "global_step": 312, "train_loss": 64.93881391867613, "train_acc": 0.42858573717948717, "xv_loss": 64.95487976074219, "xv_acc": 0.4266826923076923, "test_loss": 64.95554283337715, "test_acc": 0.4306891025641026}]]
["2024-02-01_16:30:41.804", ["EVAL ROUND", {"epoch": 3, "global_step": 624, "train_loss": 65.14669770460863, "train_acc": 0.48677884615384615, "xv_loss": 65.17096915611855, "xv_acc": 0.4742588141025641, "test_loss": 65.17001078679012, "test_acc": 0.4777644230769231}]]
["2024-02-01_16:30:54.583", ["EVAL ROUND", {"epoch": 4, "global_step": 936, "train_loss": 65.25194432185246, "train_acc": 0.582832532051282, "xv_loss": 65.28563181559245, "xv_acc": 0.5697115384615384, "test_loss": 65.29507857102614, "test_acc": 0.5674078525641025}]]
["2024-02-01_16:31:08.761", ["EVAL ROUND", {"epoch": 5, "global_step": 1248, "train_loss": 65.50273318168445, "train_acc": 0.6300080128205128, "xv_loss": 65.53921655508188, "xv_acc": 0.6197916666666666, "test_loss": 65.54822305532602, "test_acc": 0.610176282051282}]]
["2024-02-01_16:31:24.060", ["EVAL ROUND", {"epoch": 6, "global_step": 1560, "train_loss": 65.77631994394156, "train_acc": 0.6498397435897436, "xv_loss": 65.82688473432492, "xv_acc": 0.6308092948717948, "test_loss": 65.83921412932567, "test_acc": 0.6272035256410257}]]
["2024-02-01_16:31:38.135", ["EVAL ROUND", {"epoch": 7, "global_step": 1872, "train_loss": 66.08040971022386, "train_acc": 0.6667668269230769, "xv_loss": 66.14017721322867, "xv_acc": 0.6444310897435898, "test_loss": 66.15226002228566, "test_acc": 0.6402243589743589}]]
["2024-02-01_16:31:41.334", ["HDF5", {"global_step": 2000, "matrix": "batch_parameters", "split": "batch", "status": "saved"}]]
["2024-02-01_16:31:41.549", ["TRAINING BATCH", {"global_step": 2000, "epoch": 7, "batch_loss": 1.025834083557129, "H_train_loss": 0.8865722980499268, "H_test_loss": 1.0292116794586181, "lr": 0.022610510812765}]]
["2024-02-01_16:31:51.598", ["EVAL ROUND", {"epoch": 8, "global_step": 2184, "train_loss": 66.36580579708784, "train_acc": 0.6808894230769231, "xv_loss": 66.44751837314703, "xv_acc": 0.6555488782051282, "test_loss": 66.45848601903671, "test_acc": 0.6551482371794872}]]
["2024-02-01_16:32:05.299", ["EVAL ROUND", {"epoch": 9, "global_step": 2496, "train_loss": 66.61758364163913, "train_acc": 0.7191506410256411, "xv_loss": 66.72313690185547, "xv_acc": 0.6824919871794872, "test_loss": 66.74005537766676, "test_acc": 0.6834935897435898}]]
["2024-02-01_16:32:20.591", ["EVAL ROUND", {"epoch": 10, "global_step": 2808, "train_loss": 66.97029514801808, "train_acc": 0.7119391025641025, "xv_loss": 67.09897114680363, "xv_acc": 0.6776842948717948, "test_loss": 67.1121938656538, "test_acc": 0.668770032051282}]]
["2024-02-01_16:32:35.266", ["EVAL ROUND", {"epoch": 11, "global_step": 3120, "train_loss": 67.26730346679688, "train_acc": 0.7307692307692307, "xv_loss": 67.40320567595653, "xv_acc": 0.6936097756410257, "test_loss": 67.42352128640199, "test_acc": 0.6868990384615384}]]
["2024-02-01_16:32:48.512", ["EVAL ROUND", {"epoch": 12, "global_step": 3432, "train_loss": 67.50553747323843, "train_acc": 0.7795472756410257, "xv_loss": 67.66564070872771, "xv_acc": 0.7231570512820513, "test_loss": 67.68948070819562, "test_acc": 0.7174479166666666}]]
["2024-02-01_16:33:01.520", ["EVAL ROUND", {"epoch": 13, "global_step": 3744, "train_loss": 67.84928571260892, "train_acc": 0.7893629807692307, "xv_loss": 68.03275064321664, "xv_acc": 0.7243589743589743, "test_loss": 68.05306879679362, "test_acc": 0.7172475961538461}]]
["2024-02-01_16:33:14.396", ["HDF5", {"global_step": 4000, "matrix": "batch_parameters", "split": "batch", "status": "saved"}]]
["2024-02-01_16:33:14.635", ["TRAINING BATCH", {"global_step": 4000, "epoch": 13, "batch_loss": 0.662187397480011, "H_train_loss": 0.6100461397171021, "H_test_loss": 0.8288507866859436, "lr": 0.022610510812765}]]
["2024-02-01_16:33:22.556", ["EVAL ROUND", {"epoch": 14, "global_step": 4056, "train_loss": 68.26662220099034, "train_acc": 0.7638221153846154, "xv_loss": 68.47001002385066, "xv_acc": 0.7045272435897436, "test_loss": 68.49300707303561, "test_acc": 0.6968149038461539}]]
["2024-02-01_16:33:36.896", ["EVAL ROUND", {"epoch": 15, "global_step": 4368, "train_loss": 68.53276766263522, "train_acc": 0.8111979166666666, "xv_loss": 68.76013027093349, "xv_acc": 0.7317708333333334, "test_loss": 68.78560550396259, "test_acc": 0.723457532051282}]]
["2024-02-01_16:33:49.969", ["EVAL ROUND", {"epoch": 16, "global_step": 4680, "train_loss": 68.96758407201523, "train_acc": 0.7869591346153846, "xv_loss": 69.24226604363857, "xv_acc": 0.7138421474358975, "test_loss": 69.25871100792519, "test_acc": 0.7095352564102564}]]
["2024-02-01_16:34:03.275", ["EVAL ROUND", {"epoch": 17, "global_step": 4992, "train_loss": 69.2577391404372, "train_acc": 0.8368389423076923, "xv_loss": 69.54417947622446, "xv_acc": 0.7402844551282052, "test_loss": 69.56172268207257, "test_acc": 0.7383814102564102}]]
["2024-02-01_16:34:18.603", ["EVAL ROUND", {"epoch": 18, "global_step": 5304, "train_loss": 69.62457960079878, "train_acc": 0.8548677884615384, "xv_loss": 69.93952941894531, "xv_acc": 0.7479967948717948, "test_loss": 69.95723880865636, "test_acc": 0.7423878205128205}]]
["2024-02-01_16:34:33.550", ["EVAL ROUND", {"epoch": 19, "global_step": 5616, "train_loss": 70.08517407148312, "train_acc": 0.8418469551282052, "xv_loss": 70.45328971667168, "xv_acc": 0.7278645833333334, "test_loss": 70.47311352460812, "test_acc": 0.7241586538461539}]]
["2024-02-01_16:34:46.875", ["EVAL ROUND", {"epoch": 20, "global_step": 5928, "train_loss": 70.45209434704903, "train_acc": 0.8606770833333334, "xv_loss": 70.8336298037798, "xv_acc": 0.7425881410256411, "test_loss": 70.83844854892828, "test_acc": 0.7373798076923077}]]
["2024-02-01_16:34:48.719", ["HDF5", {"global_step": 6000, "matrix": "batch_parameters", "split": "batch", "status": "saved"}]]
["2024-02-01_16:34:48.934", ["TRAINING BATCH", {"global_step": 6000, "epoch": 20, "batch_loss": 0.396763414144516, "H_train_loss": 0.4181188840866089, "H_test_loss": 0.8335136742591858, "lr": 0.022610510812765}]]
["2024-02-01_16:35:00.295", ["EVAL ROUND", {"epoch": 21, "global_step": 6240, "train_loss": 70.93289341070714, "train_acc": 0.8455528846153846, "xv_loss": 71.3567127325596, "xv_acc": 0.7229567307692307, "test_loss": 71.36930084228516, "test_acc": 0.7216546474358975}]]
["2024-02-01_16:35:15.402", ["EVAL ROUND", {"epoch": 22, "global_step": 6552, "train_loss": 71.30989837646484, "train_acc": 0.8759014423076923, "xv_loss": 71.7698858212202, "xv_acc": 0.7431891025641025, "test_loss": 71.780820504213, "test_acc": 0.7440905448717948}]]
["2024-02-01_16:35:30.659", ["EVAL ROUND", {"epoch": 23, "global_step": 6864, "train_loss": 71.72928795447716, "train_acc": 0.8903245192307693, "xv_loss": 72.22096888224284, "xv_acc": 0.7434895833333334, "test_loss": 72.23818617600661, "test_acc": 0.7463942307692307}]]
["2024-02-01_16:35:43.923", ["EVAL ROUND", {"epoch": 24, "global_step": 7176, "train_loss": 72.25764621832433, "train_acc": 0.862479967948718, "xv_loss": 72.77344561845828, "xv_acc": 0.7308693910256411, "test_loss": 72.79602461594801, "test_acc": 0.7199519230769231}]]
["2024-02-01_16:35:57.096", ["EVAL ROUND", {"epoch": 25, "global_step": 7488, "train_loss": 72.70176452245468, "train_acc": 0.8700921474358975, "xv_loss": 73.27652104695638, "xv_acc": 0.7301682692307693, "test_loss": 73.28412637955103, "test_acc": 0.7288661858974359}]]
["2024-02-01_16:36:11.645", ["EVAL ROUND", {"epoch": 26, "global_step": 7800, "train_loss": 73.0747896830241, "train_acc": 0.9027443910256411, "xv_loss": 73.68988976111778, "xv_acc": 0.7377804487179487, "test_loss": 73.69662260397887, "test_acc": 0.7359775641025641}]]
["2024-02-01_16:36:17.463", ["HDF5", {"global_step": 8000, "matrix": "batch_parameters", "split": "batch", "status": "saved"}]]
["2024-02-01_16:36:17.702", ["TRAINING BATCH", {"global_step": 8000, "epoch": 26, "batch_loss": 0.18507087230682373, "H_train_loss": 0.33417556643486024, "H_test_loss": 0.9274844970703126, "lr": 0.022610510812765}]]
["2024-02-01_16:36:24.080", ["FINAL EVALUATION", {"epoch": 27, "global_step": 8002, "train_loss": 73.34579702524039, "train_acc": 0.9142628205128205, "xv_loss": 73.96517200959035, "xv_acc": 0.7473958333333334, "test_loss": 73.98084200345554, "test_acc": 0.7451923076923077}]]
